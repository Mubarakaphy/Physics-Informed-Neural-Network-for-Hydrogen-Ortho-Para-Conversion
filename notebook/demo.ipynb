{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad064ae",
   "metadata": {},
   "source": [
    "\n",
    "# PINN Demo — Heat Diffusion + Ortho/Para Kinetics\n",
    "\n",
    "This notebook demonstrates the workflow used in the repository:\n",
    "\n",
    "1. Generate reference data with a **finite-difference (FD)** solver (heat + kinetics).\n",
    "2. Train a small **differentiable surrogate** for the equilibrium ortho-fraction $ f_{\\rm eq}(T) $ derived from statistical mechanics.\n",
    "3. Train a **Physics-Informed Neural Network (PINN)** that predicts $T(x,t)$ and $f(x,t)$ and enforces the coupled physics through residual losses.\n",
    "4. Compare **PINN vs FD** and visualize residual fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06792bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Force CPU + silence CUDA warnings (useful on some systems)\n",
    "import os, warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "warnings.filterwarnings(\"ignore\", message=\".*CUDA initialization.*\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97433c8c",
   "metadata": {},
   "source": [
    "\n",
    "## Physics model and parameters\n",
    "\n",
    "We solve, in 1D on \\(x\\in[0,L]\\) and \\(t\\in[0,t_{\\max}]\\):\n",
    "\n",
    "- Heat equation with a source from conversion heat,  \n",
    "\\[\n",
    "T_t = \\alpha T_{xx} + S, \\qquad S = -\\frac{\\Delta H}{\\rho c_p}\\frac{\\partial f}{\\partial t}\n",
    "\\]\n",
    "\n",
    "- Local kinetics,  \n",
    "\\[\n",
    "\\frac{\\partial f}{\\partial t} = -k(T)\\big(f - f_{\\rm eq}(T)\\big), \\quad k(T)=k_0 e^{-E_{\\rm act}/T}.\n",
    "\\]\n",
    "\n",
    "Below we use placeholder values for demonstration. Replace with literature values for your application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Physical parameters (demo values) ---\n",
    "L = 0.1                 # m\n",
    "t_max = 60.0            # s\n",
    "alpha = 1e-5            # m^2/s\n",
    "rho_cp = 1.0e6          # J/(m^3 K)\n",
    "DeltaH = 1e5            # J per converted \"unit\" (toy)\n",
    "k0 = 1e-3               # s^-1\n",
    "E_act = 5.0             # dimensionless in this toy Arrhenius\n",
    "\n",
    "# Boltzmann and rotational temperature (for f_eq reference)\n",
    "kB = 1.380649e-23\n",
    "Theta_rot = 85.4\n",
    "\n",
    "def E_J(J):\n",
    "    return kB * Theta_rot * J * (J + 1)\n",
    "\n",
    "def f_ortho_eq_numpy(T, Jmax=40):\n",
    "    \"\"\"Equilibrium ortho fraction from rotational partition function (numpy; slow but precise).\"\"\"\n",
    "    T = max(float(T), 1.0)\n",
    "    Js = np.arange(0, Jmax+1)\n",
    "    energies = np.exp(-np.array([E_J(J) for J in Js]) / (kB*T + 1e-30))\n",
    "    g_ns = np.where(Js % 2 == 0, 1, 3)   # nuclear spin degeneracy (para even=1, ortho odd=3)\n",
    "    degeneracy = (2*Js + 1) * g_ns\n",
    "    Z = np.sum(degeneracy * energies)\n",
    "    ortho_sum = np.sum(degeneracy[Js % 2 == 1] * energies[Js % 2 == 1])\n",
    "    return float(ortho_sum / Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f188c0",
   "metadata": {},
   "source": [
    "\n",
    "## Finite-difference (FD) reference solver\n",
    "\n",
    "We use an explicit scheme with an automatic adjustment of \\(\\Delta t\\) to satisfy the CFL condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72737085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_synthetic(L=0.1, Nx=81, t_max=60.0, Nt=301):\n",
    "    dx = L/(Nx-1)\n",
    "    x = np.linspace(0, L, Nx)\n",
    "\n",
    "    max_dt = 0.5 * dx * dx / alpha\n",
    "    dt_user = t_max/(Nt-1)\n",
    "    if dt_user > max_dt:\n",
    "        dt = max_dt\n",
    "        Nt = int(np.ceil(t_max / dt)) + 1\n",
    "        dt = t_max / (Nt - 1)\n",
    "        print(f\"[FD] Adjusted Nt to {Nt} and dt to {dt:.3e} for stability (max_dt {max_dt:.3e})\")\n",
    "    else:\n",
    "        dt = dt_user\n",
    "\n",
    "    t = np.linspace(0, t_max, Nt)\n",
    "\n",
    "    # Initial conditions\n",
    "    T = np.ones(Nx) * 20.0\n",
    "    f = np.ones(Nx) * 0.75\n",
    "    # Gaussian bump in T at center\n",
    "    T += 5.0 * np.exp(-((x - L/2)**2)/(2*(0.01)**2))\n",
    "\n",
    "    T_all = np.zeros((Nt, Nx)); T_all[0,:] = T.copy()\n",
    "    f_all = np.zeros((Nt, Nx)); f_all[0,:] = f.copy()\n",
    "\n",
    "    for n in range(1, Nt):\n",
    "        T_for = np.maximum(T, 1e-3)\n",
    "        k_vals = k0 * np.exp(-E_act / (T_for + 1e-12))\n",
    "        f_eq_vals = np.array([f_ortho_eq_numpy(Ti) for Ti in np.maximum(T, 1.0)])\n",
    "        dfdt = -k_vals * (f - f_eq_vals)\n",
    "        f_new = f + dt * dfdt\n",
    "\n",
    "        S = -DeltaH / rho_cp * dfdt\n",
    "        T_new = T.copy()\n",
    "        T_new[1:-1] = T[1:-1] + alpha * dt / dx**2 * (T[2:] - 2*T[1:-1] + T[:-2]) + dt * S[1:-1]\n",
    "        T_new[0] = 20.0; T_new[-1] = 20.0\n",
    "\n",
    "        if (np.isnan(T_new).any() or np.isnan(f_new).any() or\n",
    "            np.isinf(T_new).any() or np.isinf(f_new).any()):\n",
    "            print(f\"[FD] NaN/Inf at step {n} — truncating.\")\n",
    "            T_all = T_all[:n,:]; f_all = f_all[:n,:]; t = t[:n]; break\n",
    "\n",
    "        T = np.maximum(T_new, 1e-6)\n",
    "        f = np.clip(f_new, 0.0, 1.0)\n",
    "        T_all[n,:] = T; f_all[n,:] = f\n",
    "\n",
    "    print(f\"[FD] Generated: Nt={T_all.shape[0]}, Nx={T_all.shape[1]}, T range [{T_all.min():.3e}, {T_all.max():.3e}]\")\n",
    "    return x, t, T_all, f_all\n",
    "\n",
    "# Run FD once for demo\n",
    "x_grid, t_grid, T_all, f_all = generate_synthetic(L=L, Nx=81, t_max=t_max, Nt=301)\n",
    "\n",
    "# Quick look at centerline signals\n",
    "center_idx = np.argmin(np.abs(x_grid - L/2))\n",
    "plt.figure()\n",
    "plt.plot(t_grid, T_all[:, center_idx])\n",
    "plt.xlabel(\"t (s)\"); plt.ylabel(\"T (K)\"); plt.title(\"FD: Center temperature evolution\")\n",
    "plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t_grid, f_all[:, center_idx])\n",
    "plt.xlabel(\"t (s)\"); plt.ylabel(\"f\"); plt.title(\"FD: Center ortho-fraction evolution\")\n",
    "plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45622485",
   "metadata": {},
   "source": [
    "\n",
    "## Differentiable surrogate for \\( f_{\\rm eq}(T) \\)\n",
    "\n",
    "We train a small neural network on a dense temperature grid to reproduce the equilibrium ortho-fraction curve. The surrogate is **frozen** during PINN training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FEqSurrogate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 64), nn.Tanh(),\n",
    "            nn.Linear(64, 64), nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, T):\n",
    "        return self.net(T)\n",
    "\n",
    "def build_feq_surrogate():\n",
    "    T_grid = np.linspace(1.0, 300.0, 2000).astype(np.float32)\n",
    "    f_grid = np.array([f_ortho_eq_numpy(Ti) for Ti in T_grid], dtype=np.float32)\n",
    "    X = torch.tensor(T_grid.reshape(-1,1), dtype=torch.float32, device=device)\n",
    "    Y = torch.tensor(f_grid.reshape(-1,1), dtype=torch.float32, device=device)\n",
    "    sur = FEqSurrogate().to(device)\n",
    "    opt = torch.optim.Adam(sur.parameters(), lr=1e-3)\n",
    "    for i in range(1200):\n",
    "        opt.zero_grad()\n",
    "        y = sur(X)\n",
    "        loss = ((y - Y)**2).mean()\n",
    "        loss.backward(); opt.step()\n",
    "        if i % 300 == 0:\n",
    "            print(f\"[surrogate] iter {i:4d} loss {loss.item():.3e}\")\n",
    "    for p in sur.parameters(): p.requires_grad = False\n",
    "    return sur\n",
    "\n",
    "sur = build_feq_surrogate()\n",
    "\n",
    "def f_eq_torch(T_tensor):\n",
    "    \"\"\"T_tensor: (N,1) -> (N,1) using frozen surrogate.\"\"\"\n",
    "    return sur(T_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2b3ed",
   "metadata": {},
   "source": [
    "\n",
    "## PINN model\n",
    "\n",
    "One network predicts both fields \\(T(x,t)\\) and \\(f(x,t)\\). We normalize inputs to \\([-1,1]\\) and use the chain rule to compute derivatives in physical coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68288cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.net = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.act = nn.Tanh()\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for layer in self.net[:-1]:\n",
    "            y = self.act(layer(y))\n",
    "        return self.net[-1](y)   # [T, f]\n",
    "\n",
    "# Normalization + chain rule factors\n",
    "x_min, x_max = 0.0, L\n",
    "t_min, t_max_local = 0.0, t_max\n",
    "sx = 2.0 / (x_max - x_min)         # dx_norm/dx\n",
    "st = 2.0 / (t_max_local - t_min)   # dt_norm/dt\n",
    "\n",
    "def normalize_X_np(X):\n",
    "    Xn = X.copy()\n",
    "    Xn[:,0] = 2*(X[:,0] - x_min)/(x_max - x_min) - 1.0\n",
    "    Xn[:,1] = 2*(X[:,1] - t_min)/(t_max_local - t_min) - 1.0\n",
    "    return Xn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7f305",
   "metadata": {},
   "source": [
    "\n",
    "## Train the PINN (short demo)\n",
    "\n",
    "We use moderate settings so the demo runs quickly. For the repository script you can increase the model size, number of epochs, and enable LBFGS refinement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95aa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def train_pinn_demo(num_epochs=600, collocation_N=1800, ic_N=200, bc_N=200, data_N=250):\n",
    "    # Weights (emphasize data modestly)\n",
    "    W_RESID, W_IC, W_BC, W_DATA = 1.0, 10.0, 10.0, 10.0\n",
    "\n",
    "    # Build data arrays\n",
    "    Xmesh, Ymesh = np.meshgrid(x_grid, t_grid)\n",
    "    XT = np.vstack([Xmesh.ravel(), Ymesh.ravel()]).T\n",
    "    T_flat = T_all.ravel(); f_flat = f_all.ravel()\n",
    "\n",
    "    # Sparse measurements\n",
    "    rand_idx = np.random.choice(XT.shape[0], size=data_N, replace=False)\n",
    "    X_data = XT[rand_idx]; T_data = T_flat[rand_idx]; f_data = f_flat[rand_idx]\n",
    "\n",
    "    # Collocation (uniform)\n",
    "    x_coll = np.random.rand(collocation_N)*L\n",
    "    t_coll = np.random.rand(collocation_N)*t_max\n",
    "    X_coll = np.vstack([x_coll, t_coll]).T\n",
    "\n",
    "    # Focused collocation near center/early times\n",
    "    N_focus = collocation_N // 3\n",
    "    x_focus = (L/2) + 0.015*np.random.randn(N_focus)\n",
    "    t_focus = (0.3*t_max)*np.random.rand(N_focus)\n",
    "    X_focus = np.vstack([np.clip(x_focus, 0.0, L), np.clip(t_focus, 0.0, t_max)]).T\n",
    "    X_coll = np.vstack([X_coll, X_focus])\n",
    "\n",
    "    # IC & BC\n",
    "    x_ic = np.random.rand(ic_N)*L; t_ic = np.zeros(ic_N)\n",
    "    X_ic = np.vstack([x_ic, t_ic]).T\n",
    "    T_ic = np.interp(x_ic, x_grid, T_all[0,:])\n",
    "    f_ic = np.interp(x_ic, x_grid, f_all[0,:])\n",
    "\n",
    "    t_bc = np.random.rand(bc_N)*t_max\n",
    "    X_bc = np.vstack([np.concatenate([np.zeros(bc_N), np.ones(bc_N)*L]),\n",
    "                      np.concatenate([t_bc, t_bc])]).T\n",
    "    T_bc_vals = np.full(2*bc_N, 20.0)\n",
    "    f_bc_vals = np.concatenate([np.interp(t_bc, t_grid, f_all[:,0]),\n",
    "                                np.interp(t_bc, t_grid, f_all[:,-1])])\n",
    "\n",
    "    # Normalize coords\n",
    "    X_coll_n = normalize_X_np(X_coll)\n",
    "    X_ic_n = normalize_X_np(X_ic)\n",
    "    X_bc_n = normalize_X_np(X_bc)\n",
    "    X_data_n = normalize_X_np(X_data)\n",
    "\n",
    "    # Torch tensors\n",
    "    def to_t(arr, req=False):\n",
    "        t = torch.tensor(arr, dtype=torch.float32, device=device)\n",
    "        t.requires_grad = req\n",
    "        return t\n",
    "\n",
    "    X_coll_t = to_t(X_coll_n, req=True)\n",
    "    X_ic_t   = to_t(X_ic_n,   req=True)\n",
    "    X_bc_t   = to_t(X_bc_n,   req=True)\n",
    "    X_data_t = to_t(X_data_n, req=False)\n",
    "\n",
    "    T_ic_t = torch.tensor(T_ic, dtype=torch.float32, device=device)[:,None]\n",
    "    f_ic_t = torch.tensor(f_ic, dtype=torch.float32, device=device)[:,None]\n",
    "    T_bc_t = torch.tensor(T_bc_vals, dtype=torch.float32, device=device)[:,None]\n",
    "    f_bc_t = torch.tensor(f_bc_vals, dtype=torch.float32, device=device)[:,None]\n",
    "    T_data_t = torch.tensor(T_data, dtype=torch.float32, device=device)[:,None]\n",
    "    f_data_t = torch.tensor(f_data, dtype=torch.float32, device=device)[:,None]\n",
    "\n",
    "    # Model (moderate size for demo)\n",
    "    layers = [2, 64, 64, 64, 2]\n",
    "    model = PINN(layers).to(device)\n",
    "    with torch.no_grad():\n",
    "        final = model.net[-1]\n",
    "        if isinstance(final, nn.Linear):\n",
    "            final.bias[0].fill_(20.0); final.bias[1].fill_(0.75)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    t0 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train(); opt.zero_grad()\n",
    "\n",
    "        pred_c = model(X_coll_t); T_c = pred_c[:,0:1]; f_c = pred_c[:,1:2]\n",
    "        gT = torch.autograd.grad(T_c, X_coll_t, torch.ones_like(T_c), create_graph=True, retain_graph=True)[0]\n",
    "        T_xn, T_tn = gT[:,0:1], gT[:,1:2]\n",
    "        T_xxn = torch.autograd.grad(T_xn, X_coll_t, torch.ones_like(T_xn), create_graph=True, retain_graph=True)[0][:,0:1]\n",
    "        T_t = T_tn*st; T_xx = T_xxn*(sx**2)\n",
    "\n",
    "        gf = torch.autograd.grad(f_c, X_coll_t, torch.ones_like(f_c), create_graph=True, retain_graph=True)[0]\n",
    "        f_t = gf[:,1:2]*st\n",
    "\n",
    "        T_c_clamp = T_c.clamp(min=1e-3, max=1e5)\n",
    "        f_eq_vals = f_eq_torch(T_c_clamp)\n",
    "        k_vals = k0 * torch.exp(-E_act / (T_c_clamp + 1e-8))\n",
    "        S_c = -DeltaH / rho_cp * f_t\n",
    "\n",
    "        r_T = torch.nan_to_num(T_t - alpha*T_xx - S_c, nan=1e6, posinf=1e6, neginf=-1e6)\n",
    "        r_f = torch.nan_to_num(f_t + k_vals*(f_c - f_eq_vals), nan=1e6, posinf=1e6, neginf=-1e6)\n",
    "        loss_r = mse(r_T, torch.zeros_like(r_T)) + mse(r_f, torch.zeros_like(r_f))\n",
    "\n",
    "        pred_ic = model(X_ic_t)\n",
    "        loss_ic = mse(pred_ic[:,0:1], T_ic_t) + mse(pred_ic[:,1:2], f_ic_t)\n",
    "        pred_bc = model(X_bc_t)\n",
    "        loss_bc = mse(pred_bc[:,0:1], T_bc_t) + mse(pred_bc[:,1:2], f_bc_t)\n",
    "\n",
    "        pred_d = model(X_data_t)\n",
    "        loss_data = mse(pred_d[:,0:1], T_data_t) + mse(pred_d[:,1:2], f_data_t)\n",
    "\n",
    "        loss = W_RESID*loss_r + W_IC*loss_ic + W_BC*loss_bc + W_DATA*loss_data\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        opt.step()\n",
    "\n",
    "        if epoch % 100 == 0 or epoch == num_epochs-1:\n",
    "            print(f\"Epoch {epoch:4d}: Loss {loss.item():.3e}, resid {loss_r.item():.3e}, ic {loss_ic.item():.3e}, data {loss_data.item():.3e}\")\n",
    "\n",
    "    print(f\"[Adam] done in {time.time()-t0:.1f}s\")\n",
    "    return model\n",
    "\n",
    "model = train_pinn_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30acde96",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation: PINN vs FD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462786f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build visualization grid\n",
    "Nx_vis = 101; Nt_vis = 101\n",
    "xv = np.linspace(0, L, Nx_vis); tv = np.linspace(0, t_max, Nt_vis)\n",
    "X_vis = np.array([[xi, ti] for ti in tv for xi in xv])\n",
    "X_vis_n = normalize_X_np(X_vis)\n",
    "X_vis_t = torch.tensor(X_vis_n, dtype=torch.float32, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(X_vis_t).cpu().numpy()\n",
    "T_pred = pred[:,0].reshape(Nt_vis, Nx_vis)\n",
    "f_pred = pred[:,1].reshape(Nt_vis, Nx_vis)\n",
    "\n",
    "# Interpolate FD to same grid\n",
    "spline_T = RectBivariateSpline(t_grid, x_grid, T_all)\n",
    "spline_f = RectBivariateSpline(t_grid, x_grid, f_all)\n",
    "T_ref = np.array([spline_T(ti, xv) for ti in tv]).reshape(Nt_vis, Nx_vis)\n",
    "f_ref = np.array([spline_f(ti, xv) for ti in tv]).reshape(Nt_vis, Nx_vis)\n",
    "\n",
    "rmse_T = np.sqrt(np.mean((T_pred - T_ref)**2))\n",
    "rmse_f = np.sqrt(np.mean((f_pred - f_ref)**2))\n",
    "print(f\"RMSE T: {rmse_T:.4e} K, RMSE f: {rmse_f:.4e}\")\n",
    "\n",
    "# Centerline traces\n",
    "center_idx = Nx_vis//2\n",
    "plt.figure()\n",
    "plt.plot(tv, T_pred[:, center_idx], label=\"PINN T center\")\n",
    "T_ref_center = np.interp(tv, t_grid, T_all[:, np.argmin(np.abs(x_grid - xv[center_idx]))])\n",
    "plt.plot(tv, T_ref_center, \"--\", label=\"FD ref T center\")\n",
    "plt.xlabel(\"t (s)\"); plt.ylabel(\"T (K)\"); plt.title(\"Center temperature evolution\"); plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tv, f_pred[:, center_idx], label=\"PINN f center\")\n",
    "f_ref_center = np.interp(tv, t_grid, f_all[:, np.argmin(np.abs(x_grid - xv[center_idx]))])\n",
    "plt.plot(tv, f_ref_center, \"--\", label=\"FD ref f center\")\n",
    "plt.xlabel(\"t (s)\"); plt.ylabel(\"f\"); plt.title(\"Center ortho-fraction evolution\"); plt.legend(); plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a23f0",
   "metadata": {},
   "source": [
    "\n",
    "## PDE residual fields\n",
    "\n",
    "We visualize the magnitudes of residuals \\( r_T = T_t - \\alpha T_{xx} - S \\) and \\( r_f = f_t + k(T)(f-f_{\\rm eq}) \\) over the space-time grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute residuals on the visualization grid\n",
    "X_vis_t.requires_grad = True\n",
    "pred_vis = model(X_vis_t)\n",
    "T_v = pred_vis[:,0:1]\n",
    "f_v = pred_vis[:,1:2]\n",
    "\n",
    "gT = torch.autograd.grad(T_v, X_vis_t, torch.ones_like(T_v), create_graph=True)[0]\n",
    "T_xn, T_tn = gT[:,0:1], gT[:,1:2]\n",
    "T_xxn = torch.autograd.grad(T_xn, X_vis_t, torch.ones_like(T_xn), create_graph=True)[0][:,0:1]\n",
    "T_t = T_tn*st; T_xx = T_xxn*(sx**2)\n",
    "\n",
    "gf = torch.autograd.grad(f_v, X_vis_t, torch.ones_like(f_v), create_graph=True)[0]\n",
    "f_t = gf[:,1:2]*st\n",
    "\n",
    "T_vc = T_v.clamp(min=1e-3)\n",
    "kvals = k0 * torch.exp(-E_act / (T_vc + 1e-8))\n",
    "f_eq_vals = f_eq_torch(T_vc)\n",
    "S_v = -DeltaH / rho_cp * f_t\n",
    "\n",
    "rT = (T_t - alpha*T_xx - S_v).detach().cpu().numpy().reshape(Nt_vis, Nx_vis)\n",
    "rf = (f_t + kvals*(f_v - f_eq_vals)).detach().cpu().numpy().reshape(Nt_vis, Nx_vis)\n",
    "\n",
    "# Heatmaps\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"abs(r_T)\")\n",
    "plt.imshow(np.abs(rT), extent=[0, L, tv[-1], tv[0]], aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"abs(r_f)\")\n",
    "plt.imshow(np.abs(rf), extent=[0, L, tv[-1], tv[0]], aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217c9bd",
   "metadata": {},
   "source": [
    "\n",
    "## Save figures for README (optional)\n",
    "\n",
    "Run this cell to save key plots under `figures/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "# Recreate and save the two main plots\n",
    "plt.figure()\n",
    "plt.plot(tv, T_pred[:, center_idx], label=\"PINN T center\")\n",
    "plt.plot(tv, T_ref_center, \"--\", label=\"FD ref T center\")\n",
    "plt.xlabel(\"t (s)\"); plt.ylabel(\"T (K)\"); plt.title(\"Center temperature evolution\"); plt.legend(); plt.grid(True)\n",
    "plt.savefig(\"figures/center_T_vs_time.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tv, f_pred[:, center_idx], label=\"PINN f center\")\n",
    "plt.plot(tv, f_ref_center, \"--\", label=\"FD ref f center\")\n",
    "plt.xlabel(\"t (s)\"); plt.ylabel(\"f\"); plt.title(\"Center ortho-fraction evolution\"); plt.legend(); plt.grid(True)\n",
    "plt.savefig(\"figures/center_f_vs_time.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.title(\"abs(r_T)\"); plt.imshow(np.abs(rT), extent=[0, L, tv[-1], tv[0]], aspect=\"auto\"); plt.colorbar()\n",
    "plt.subplot(1,2,2); plt.title(\"abs(r_f)\"); plt.imshow(np.abs(rf), extent=[0, L, tv[-1], tv[0]], aspect=\"auto\"); plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/residuals.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved figures to ./figures\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
